{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4024bf12-53c5-4f8e-8994-a5b0073cdb08",
   "metadata": {},
   "source": [
    "This is where the magic happens:\n",
    "\n",
    "# MODELLING\n",
    "\n",
    "In this notebook I'll work on a model to what a tourist will spend when vacationing in Tanzania.\n",
    "The evaluation metric for the model is **Mean Absolute Error**.\n",
    "\n",
    "\n",
    "To do:\n",
    "- feature selection/feature engineering (subregions)\n",
    "- model\n",
    "- again if necessary: feature selection/feature engineering\n",
    "- outlier handling (Isolation Forest?)\n",
    "- hyperparameter tuning\n",
    "- interpretation/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e6b52b5-7a23-477c-af5a-c0a60112e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some packages that I'll need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set color scheme\n",
    "cpal = [\"#f94144\",\"#f3722c\",\"#f8961e\",\"#f9844a\",\"#f9c74f\",\"#90be6d\",\"#43aa8b\",\"#4d908e\",\"#577590\",\"#277da1\"]\n",
    "\n",
    "# seaborn theme\n",
    "sns.set()\n",
    "\n",
    "# use natural numbers\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# set random seed\n",
    "RSEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7607d78f-5887-42b8-87ea-f75ffeb7473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TZA = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b7ecb-d705-4303-a9e5-e7bbae09acb0",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "I'm going to split the train and test data now, very in the beginning to avoid data leakage.\n",
    "\n",
    "I'm not using the regular sklear train test split as it gave me concerning results in the first run (much better performance on test than on train data). That's why I use Verstack stratified continuos split which allows me to stratify by continuos target variable. (It makes sure that different bins of total_cost are evenly divided among train and test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c20b6d6-24bc-47b0-b8d4-b1d7ad0a1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, test = scsplit(TZA, stratify = TZA['total_cost'], test_size = 0.3, random_state = RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee23e65-64a9-4f27-9cd5-a9bf3c002d56",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "I am going to preprocess the data now. I'll do it separately for train and test data.\n",
    "\n",
    "#### Missing values and minor adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c6478a-3918-4b32-857b-83a4fc61c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle missing data and to make some minor adjustments on the dataset\n",
    "\n",
    "def basic_preprocessing(df):\n",
    "    # fill NaN total_male/total_female with 0\n",
    "    df['total_male'] = df['total_male'].fillna(0)\n",
    "    df['total_female'] = df['total_female'].fillna(0)\n",
    "    \n",
    "    # fill NaN travel_with with \"Alone\" if total_male plus total_female is one\n",
    "    df.loc[df['total_female'] + df['total_male'] == 1, 'travel_with'] = 'Alone'\n",
    "    \n",
    "    # fill remaining NaN travel_with with missing\n",
    "    df['travel_with'] = df['travel_with'].fillna('missing')\n",
    "    \n",
    "    # fill NaN most_impressing with \"No comments\"\n",
    "    df['most_impressing'] = df['most_impressing'].fillna('No comments')\n",
    "   \n",
    "    # drop id column\n",
    "    df = df.drop(['ID'], axis =1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4daee7b0-2ab1-4178-9bfa-5304f338d6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply function on train data\n",
    "train = basic_preprocessing(train)\n",
    "# apply function on test data\n",
    "test = basic_preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc87ef02-6700-458f-a8fc-f8a585349e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target variable, both in train and test data\n",
    "\n",
    "X_train = train.drop(['total_cost'], axis=1)\n",
    "y_train = train['total_cost']\n",
    "\n",
    "X_test = test.drop(['total_cost'], axis=1)\n",
    "y_test = test['total_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0062dea-f1dd-4fd5-9de6-f9708c8b59d3",
   "metadata": {},
   "source": [
    "### Build Pipelines\n",
    "\n",
    "I'm going to build some pipelines now. They'll make modelling easier and faster.\n",
    "\n",
    "I start with a pipeline for the categorical features. I use a One Hot Encoder to convert them into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98500513-dc9d-4e66-8189-c6250bee8f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of categorical features\n",
    "cat_features = list(X_train.columns[X_train.dtypes==object])\n",
    "\n",
    "# build pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown= 'ignore', drop = 'first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d64a46-f56c-4fc0-a124-fba6edf79f72",
   "metadata": {},
   "source": [
    "For the numerical features I'll use a Robust Scaler. It can handle outliers pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf948b9a-bedd-4f8b-8448-35c457319201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of numerical features\n",
    "num_features = list(X_train.columns[X_train.dtypes!=object])\n",
    "\n",
    "# build pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('rob_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba64739-0e4a-43d5-8351-f66de99d4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both pipelines in a preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114112e0-67a1-440f-80f6-15d29c4f3081",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "First I'm going to train a linear regression model. Except for some NaN imputations and the basic preprocessing we haven't made adjustments on the data yet. The result of the Baseline Model will serve me as a benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f400d5-ac51-418a-b52b-0775ca49d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline that combines the preprocessor and the linear regression model\n",
    "pipe_linreg_bl = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('linreg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e508a439-dd51-4b55-a34b-5394430fe6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Baseline Model (train data): 5858302.30\n"
     ]
    }
   ],
   "source": [
    "# cross validate to check how the model performs on the train data\n",
    "y_train_predicted_bl_cv = cross_val_predict(pipe_linreg_bl, X_train, y_train, cv=100)\n",
    "\n",
    "# print MAE of Baseline Model (train data)\n",
    "print(\"Mean Absolute Error Baseline Model (train data): {:.2f}\".format(mean_absolute_error(y_train, y_train_predicted_bl_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ec3dec-8819-4f1c-a19e-ee38213cee83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Baseline Model (test data): 5895242.84\n"
     ]
    }
   ],
   "source": [
    "# fit the actual model\n",
    "y_train_predicted_bl = pipe_linreg_bl.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for the test data\n",
    "y_test_predicted_bl = pipe_linreg_bl.predict(X_test)\n",
    "# print MAE of Baseline Model (test data)\n",
    "print(\"Mean Absolute Error Baseline Model (test data): {:.2f}\".format(mean_absolute_error(y_test, y_test_predicted_bl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db632f4b-23dc-4ae5-8114-13f0a8574426",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The Mean Absolute Error of the Baseline Model is 5895242.84 Tanzanian Schillig TZS.\n",
    "What does that mean?\n",
    "The MAE is the sum of absolute errors divided by the sample size $n$ where $y_i$ is the prediction and $x_i$ is the true value:\n",
    "\n",
    "$$ \n",
    "MAE = \\frac {\\sum_{i=1}^n \\vert y_i - x_i \\vert} {n}\n",
    "$$\n",
    "\n",
    "The MAE uses the same scale as the data, so in this case TZS. \n",
    "\n",
    "So, on average, the model's predictions are 5895242.84 TZS off the true value. This is roughly 2156 Euro and seems quite a lot. \n",
    "\n",
    "Our aim is to improve (lower) this metric as much as we can.\n",
    "\n",
    "So let's start with the actual \n",
    "\n",
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a8290-8018-4ba2-a951-2ac93fe3b3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02c9e8-d17a-4973-aba7-9bde9bf94bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
